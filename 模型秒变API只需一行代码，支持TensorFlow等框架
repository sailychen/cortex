模型秒变API只需一行代码，支持TensorFlow等框架
我爱计算机视觉 11月25日
点击我爱计算机视觉标星，更快获取CVML新技术



本文转自机器之心

参与：一鸣、杜伟

还在为机器学习模型打包成 API 发愁？这个工具能让你一行代码直接打包。


专注于机器学习应用的人们知道，从训练好的模型到实际的工业生产工具还有一定的距离。其中工作量很大的地方在于将模型打包，预留 API 接口，并和现有的生产系统相结合。近日，GitHub 上有了这样一个项目，能够让用户一行代码将任意模型打包为 API。这一工具无疑能够帮助开发者在实际的生产应用中快速部署模型。


项目地址：https://github.com/cortexlabs/cortex


项目特点和原理


该项目名为 Cortex，是一个命令行工具。作者表示，该项目具有以下优点：


自动定义：Cortex 可以自动定义需要负责生产工作的 API；

多框架支持：Cortex 支持多种机器学习框架，包括 TensorFlow、PyTorch、scikit-learn、XGBoost 等；

CPU/GPU 支持：Cortex 能够在 CPU 或者 GPU 上进行推理工作；

回滚式更新：Cortex 可以对部署的 API 直接更新；

日志流：Cortex 会保留部署模型的日志流，并在 CLI 上显示；

预测监控：Cortex 能够监控网络的评价指标，并追踪预测结果；

最小配置：部署时，用户只需要在一个名为 cortex.yaml 的文件中配置相关属性。







这一项目是怎样工作的？具体而言，每当用户运行 cortex deploy 时，命令行将配置属性和代码发送到服务器集群上。每个模型都载入到一个 Docker 容器中，包括相关的 Python 包和处理请求的代码。模型通过网络服务，如 Elastic Load Balancing (ELB)、Flask、TensorFlow Serving 和 ONNX Runtime 公开 API 给用户使用。容器通过 Elastic Kubernetes Service (EKS) 进行控制，而日志文件和评价指标的记录和打印工作由 CloudWatch 完成。


使用方法


使用过程主要分为以下三个步骤：


定义模型的 API


# predictor.py

model = download_my_model()
def predict(sample, metadata):        
    return model.predict(sample["text"])


如上所示，用户需要做的是定义代表这个 API 的函数，使其能够根据输入数据返回输出。


配置部署


# cortex.yaml

- kind: deploymentname: sentiment

- kind: apiname: classifierpredictor:
        path: predictor.pytracker:
        model_type: classificationcompute:
        gpu: 1

第二个步骤中，用户需要创建一个新的 yaml 文件，这个文件用于配置相关属性。


具体而言，用户可以定义部署模型的名称，本例中名为 classifierpredictor。然后还需要定义 API 的名称，如 classifierpredictor 以及路径、模型的类型和使用的 GPU 数量等。


AWS 部署


$ cortex deploy

creating classifier (http://***.amazonaws.com/sentiment/classifier)


以 AWS 为例，以上工作完成后，用户可以创建这个 API，使其利用 AWS 进行工作。


当然，用户还可以实时保存推断结果，如下所示：


$ curl http://***.amazonaws.com/sentiment/classifier \
-X POST -H "Content-Type: application/json" \
-d '{"text": "the movie was great!"}'

positive

此外，用户还可以监控运行结果。


$ cortex get classifier --watch

status up-to-date available requested last update avg latency
live 1 1 1 8s 123ms

class count
positive 8
negative 4

使用教程


为了让用户更好地使用这一工具，项目作者同时还提供了一些使用案例。包括：

基于 TensorFlow 和 BERT 进行情感分析：https://github.com/cortexlabs/cortex/tree/0.10/examples/tensorflow/sentiment-analysis

基于 TensorFlow 和 Inception 模型进行图像分类：https://github.com/cortexlabs/cortex/tree/0.10/examples/tensorflow/image-classifier

基于 PyTorch 和 DistilGPT2 进行文本生成：https://github.com/cortexlabs/cortex/tree/0.10/examples/pytorch/text-generator

基于 XGBoost / ONNX 进行虹膜分类：https://github.com/cortexlabs/cortex/tree/0.10/examples/xgboost/iris-classifier



以使用 BERT 进行情感分析为例：


首先用户需要在模型上定义 API 接口函数，使其可以通过函数输入数据，并返回模型的推理结果。这一 py 文件被定义为 handler.py：


# handler.py

import tensorflow as tf
import tensorflow_hub as hub
from bert import tokenization, run_classifier

labels = ["negative", "positive"]

with tf.Graph().as_default():
    bert_module = hub.Module("https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1")
    info = bert_module(signature="tokenization_info", as_dict=True)
with tf.Session() as sess:
    vocab_file, do_lower_case = sess.run([info["vocab_file"], info["do_lower_case"]])
    tokenizer = tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)


def pre_inference(sample, signature, metadata):
    input_example = run_classifier.InputExample(guid="", text_a=sample["review"], label=0)
    input_feature = run_classifier.convert_single_example(0, input_example, [0, 1], 128, tokenizer)
    return {"input_ids": [input_feature.input_ids]}


def post_inference(prediction, signature, metadata):
    return labels[prediction["labels"][0]]

接着，用户需要定义配置 yaml 文件，在文件中指定相关属性，这里需要注意，文件名必须定义为 cortex.yaml：


# cortex.yaml

- kind: deployment
  name: sentiment

- kind: api
  name: classifier
  tensorflow:
    model: s3://cortex-examples/tensorflow/sentiment-analysis/bert
    request_handler: handler.py
  tracker:
    model_type: classification

从中可以看到，yaml 文件中需要指定出使用的模型，以及作为 API 接口的 py 文件（即第一步中定义了的 py 文件）。


然后进行部署即可：


$ cortex deploy

deployment started

如果需要获得监控信息，则需要输入 cortex get 命令：


$ cortex get classifier --watch

status up-to-date available requested last update avg latency
live 1 1 1 8s

还可以用命令行获得实时预测：


$ cortex get classifier

url: http://***.amazonaws.com/sentiment/classifier

$ curl http://***.amazonaws.com/sentiment/classifier \
  -X POST -H "Content-Type: application/json" \
  -d '{"review": "The movie was great!"}'"positive






模型压缩与应用部署交流群



关注最新最前沿的模型压缩、轻量级模型设计、量化剪枝、知识蒸馏、推断部署技术，扫码添加CV君拉你入群，（如已为CV君其他账号好友请直接私信）

（请务必注明：部署）



喜欢在QQ交流的童鞋，可以加52CV官方QQ群：805388940。

（不会时时在线，如果没能及时通过验证还请见谅）





长按关注我爱计算机视觉


微信扫一扫
关注该公众号
